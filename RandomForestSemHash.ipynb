{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#coding: utf-8\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import unicode_literals\n",
    "import re\n",
    "import os\n",
    "import codecs\n",
    "import json\n",
    "import csv\n",
    "import spacy\n",
    "import sklearn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import model_selection\n",
    "from time import time\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, HashingVectorizer, CountVectorizer\n",
    "from sklearn.feature_selection import SelectFromModel, SelectKBest, chi2\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.neighbors.nearest_centroid import NearestCentroid\n",
    "import math\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "from matplotlib.ticker import ScalarFormatter\n",
    "from matplotlib import ticker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp=spacy.load('en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "intent_dict_AskUbuntu = {\"Make Update\":0, \"Setup Printer\":1, \"Shutdown Computer\":2, \"Software Recommendation\":3, \"None\":4}\n",
    "intent_dict_Chatbot = {\"DepartureTime\":0, \"FindConnection\":1}\n",
    "intent_dict_WebApplications = {\"Download Video\":0, \"Change Password\":1, \"None\":2, \"Export Data\":3, \"Sync Accounts\":4,\n",
    "                  \"Filter Spam\":5, \"Find Alternative\":6, \"Delete Account\":7}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#********* Data augmentation part **************\n",
    "class MeraDataset():\n",
    "    \"\"\" Class to find typos based on the keyboard distribution, for QWERTY style keyboards\n",
    "    \n",
    "        It's the actual test set as defined in the paper that we comparing against.\"\"\"\n",
    "\n",
    "    def __init__(self, dataset_path, augmentedFile, n_splits=3, ratio=0.3, augment=False, nSamples=1):\n",
    "        \"\"\" Instantiate the object.\n",
    "            @param: dataset_path The directory which contains the data set.\n",
    "            @param: n_splits For the stratified_split, not in use here (default 0.3).\n",
    "            @param: ratio  For the stratified_split, not in use here (default 0.3).\n",
    "            @param: augment If the data set should be augmented (default False)\"\"\"\n",
    "        self.dataset_path = dataset_path\n",
    "        self.nSamples = nSamples\n",
    "        self.augment = augment\n",
    "        self.augmentedFile = augmentedFile\n",
    "        self.n_splits = n_splits\n",
    "        self.ratio = ratio\n",
    "        self.X_test, self.y_test, self.X_train, self.y_train = self.load()\n",
    "        self.keyboard_cartesian = {'q': {'x': 0, 'y': 0}, 'w': {'x': 1, 'y': 0}, 'e': {'x': 2, 'y': 0},\n",
    "                                   'r': {'x': 3, 'y': 0}, 't': {'x': 4, 'y': 0}, 'y': {'x': 5, 'y': 0},\n",
    "                                   'u': {'x': 6, 'y': 0}, 'i': {'x': 7, 'y': 0}, 'o': {'x': 8, 'y': 0},\n",
    "                                   'p': {'x': 9, 'y': 0}, 'a': {'x': 0, 'y': 1}, 'z': {'x': 0, 'y': 2},\n",
    "                                   's': {'x': 1, 'y': 1}, 'x': {'x': 1, 'y': 2}, 'd': {'x': 2, 'y': 1},\n",
    "                                   'c': {'x': 2, 'y': 2}, 'f': {'x': 3, 'y': 1}, 'b': {'x': 4, 'y': 2},\n",
    "                                   'm': {'x': 5, 'y': 2}, 'j': {'x': 6, 'y': 1}, 'g': {'x': 4, 'y': 1},\n",
    "                                   'h': {'x': 5, 'y': 1}, 'j': {'x': 6, 'y': 1}, 'k': {'x': 7, 'y': 1},\n",
    "                                   'l': {'x': 8, 'y': 1}, 'v': {'x': 3, 'y': 2}, 'n': {'x': 5, 'y': 2},\n",
    "                                   'ß': {'x': 10,'y': 2}, 'ü': {'x': 10,'y': 2}, 'ä': {'x': 10,'y': 0},\n",
    "                                   'ö': {'x': 11,'y': 0}}\n",
    "        self.nearest_to_i = self.get_nearest_to_i(self.keyboard_cartesian)\n",
    "        self.splits = self.stratified_split()\n",
    "\n",
    "\n",
    "    def get_nearest_to_i(self, keyboard_cartesian):\n",
    "        \"\"\" Get the nearest key to the one read.\n",
    "            @params: keyboard_cartesian The layout of the QWERTY keyboard for English\n",
    "            \n",
    "            return dictionary of eaculidean distances for the characters\"\"\"\n",
    "        nearest_to_i = {}\n",
    "        for i in keyboard_cartesian.keys():\n",
    "            nearest_to_i[i] = []\n",
    "            for j in keyboard_cartesian.keys():\n",
    "                if self._euclidean_distance(i, j) > 1.2:\n",
    "                    nearest_to_i[i].append(j)\n",
    "        return nearest_to_i\n",
    "\n",
    "    def _shuffle_word(self, word, cutoff=0.9):\n",
    "        \"\"\" Rearange the given characters in a word simulating typos given a probability.\n",
    "        \n",
    "            @param: word A single word coming from a sentence\n",
    "            @param: cutoff The cutoff probability to make a change (default 0.9)\n",
    "            \n",
    "            return The word rearranged \n",
    "            \"\"\"\n",
    "        word = list(word.lower())\n",
    "        if random.uniform(0, 1.0) > cutoff:\n",
    "            loc = np.random.randint(0, len(word))\n",
    "            if word[loc].isalpha():\n",
    "                word[loc] = random.choice(self.nearest_to_i[word[loc]])\n",
    "        return ''.join(word)\n",
    "\n",
    "    def _euclidean_distance(self, a, b):\n",
    "        \"\"\" Calculates the euclidean between 2 points in the keyboard\n",
    "            @param: a Point one \n",
    "            @param: b Point two\n",
    "            \n",
    "            return The euclidean distance between the two points\"\"\"\n",
    "        X = (self.keyboard_cartesian[a]['x'] - self.keyboard_cartesian[b]['x']) ** 2\n",
    "        Y = (self.keyboard_cartesian[a]['y'] - self.keyboard_cartesian[b]['y']) ** 2\n",
    "        return math.sqrt(X + Y)\n",
    "\n",
    "    def _augment_sentence(self, sentence, num_samples):\n",
    "        \"\"\" Augment the dataset of file with a sentence shuffled\n",
    "            @param: sentence The sentence from the set\n",
    "            @param: num_samples The number of sentences to genererate\n",
    "            \n",
    "            return A set of augmented sentences\"\"\"\n",
    "        sentences = []\n",
    "        for _ in range(num_samples):\n",
    "            sentences.append(' '.join([self._shuffle_word(item) for item in sentence.split(' ')]))\n",
    "        sentences = list(set(sentences))\n",
    "        # print(\"sentences\", sentences)\n",
    "        return sentences + [sentence]\n",
    "\n",
    "    def _augment_split(self, X_train, y_train, num_samples=100):\n",
    "        \"\"\" Split the augmented train dataset\n",
    "            @param: X_train The full array of sentences\n",
    "            @param: y_train The train labels in the train dataset\n",
    "            @param: num_samples the number of new sentences to create (default 1000)\n",
    "            \n",
    "            return Augmented training dataset\"\"\"\n",
    "        Xs, ys = [], []\n",
    "        for X, y in zip(X_train, y_train):\n",
    "            tmp_x = self._augment_sentence(X, num_samples)\n",
    "            sample = [[Xs.append(item), ys.append(y)] for item in tmp_x]\n",
    "#             print(X, y)\n",
    "#             print(self.augmentedFile+str(self.nSamples)+\".csv\")\n",
    "            \n",
    "        with open(self.augmentedFile+str(self.nSamples)+\".csv\", 'w', encoding='utf8') as csvFile:\n",
    "            fileWriter = csv.writer(csvFile, delimiter='\\t')\n",
    "            for i in range(0, len(Xs)-1):\n",
    "                fileWriter.writerow([Xs[i] + '\\t' + ys[i]])\n",
    "                # print(Xs[i], \"\\t\", ys[i])\n",
    "                # print(Xs[i])\n",
    "            # fileWriter.writerows(Xs + ['\\t'] + ys)\n",
    "        return Xs, ys\n",
    "\n",
    "    def load(self):\n",
    "        \"\"\" Load the file for now only the test.csv, train.csv files hardcoded\n",
    "        \n",
    "            return The vector separated in test, train and the labels for each one\"\"\"\n",
    "        i = 0\n",
    "        \n",
    "        with open(self.dataset_path) as csvfile:\n",
    "            readCSV = csv.reader(csvfile, delimiter='\t')\n",
    "            all_rows = list(readCSV)\n",
    "#             print(all_rows)\n",
    "#             for i in all_rows:\n",
    "#                 if i ==  28823:\n",
    "#                     print(all_rows[i])\n",
    "            X_test = [a[0] for a in all_rows]\n",
    "            y_test = [a[1] for a in all_rows]\n",
    "\n",
    "        with open(self.dataset_path) as csvfile:\n",
    "            readCSV = csv.reader(csvfile, delimiter='\\t')\n",
    "            all_rows = list(readCSV)\n",
    "#             print(all_rows)\n",
    "            \n",
    "            X_train = [a[0] for a in all_rows]\n",
    "            y_train = [a[1] for a in all_rows]\n",
    "        return X_test, y_test, X_train, y_train\n",
    "\n",
    "    def process_sentence(self, x):\n",
    "        \"\"\" Clean the tokens from stop words in a sentence.\n",
    "            @param x Sentence to get rid of stop words.\n",
    "            \n",
    "            returns clean string sentence\"\"\"\n",
    "        clean_tokens = []\n",
    "        doc = nlp.tokenizer(x)\n",
    "        for token in doc:\n",
    "            if not token.is_stop:\n",
    "                clean_tokens.append(token.lemma_)\n",
    "        return \" \".join(clean_tokens)\n",
    "\n",
    "    def process_batch(self, X):\n",
    "        \"\"\"See the progress as is coming along.\n",
    "        \n",
    "            return list[] of clean sentences\"\"\"\n",
    "        return [self.process_sentence(a) for a in tqdm(X)]\n",
    "\n",
    "    def stratified_split(self):\n",
    "        \"\"\" Split data whole into stratified test and training sets, then remove stop word from sentences\n",
    "        \n",
    "            return list of dictionaries with keys train,test and values the x and y for each one\"\"\"\n",
    "\n",
    "        self.X_train, self.y_train = self._augment_split(self.X_train,\n",
    "                                                         self.y_train, num_samples=self.nSamples)\n",
    "#         self.X_train = self.process_batch(self.X_train)\n",
    "#         self.X_test = self.process_batch(self.X_test)\n",
    "\n",
    "        splits = [{\"train\": {\"X\": self.X_train, \"y\": self.y_train},\n",
    "                   \"test\": {\"X\": self.X_test, \"y\": self.y_test}}]\n",
    "#         print(splits[0][\"train\"][\"y\"])\n",
    "        return splits\n",
    "\n",
    "    def get_splits(self):\n",
    "        \"\"\" Get the splitted sentences\n",
    "            \n",
    "            return splitted list of dictionaries\"\"\"\n",
    "        return self.splits\n",
    "#****************************************************"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmark_dataset = 'AskUbuntu' #choose from 'AskUbuntu', 'Chatbot' or 'WebApplication'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename_train = \"datasets/KL/\" + benchmark_dataset + \"/train.csv\"\n",
    "filename_test = \"datasets/KL/\" + benchmark_dataset + \"/test.csv\"\n",
    "\n",
    "filename_augmented = \"./datasets/KL/\" + benchmark_dataset + \"/train_augmented\"\n",
    "numAug = 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_CSV_datafile(filename):    \n",
    "    X = []\n",
    "    y = []\n",
    "    with open(filename, 'r') as csvfile:\n",
    "        reader = csv.reader(csvfile, delimiter='\\t')\n",
    "        for row in reader:\n",
    "            X.append(row[0])\n",
    "            if benchmark_dataset == 'AskUbuntu':\n",
    "                y.append(intent_dict_AskUbuntu[row[1]])\n",
    "            elif benchmark_dataset == 'Chatbot':\n",
    "                y.append(intent_dict_Chatbot[row[1]])\n",
    "            else:\n",
    "                y.append(intent_dict_WebApplications[row[1]])           \n",
    "    return X,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./datasets/KL/AskUbuntu/train.csv\n",
      "mera****************************\n",
      "['how to rocord my screen?', 'how tf record my screen?', 'How to record my screen?']\n",
      "[4, 4, 4, 4, 4, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"./datasets/KL/\" + benchmark_dataset + \"/train.csv\")\n",
    "dataset = MeraDataset(\"./datasets/KL/\" + benchmark_dataset + \"/train.csv\", ratio=0.2, nSamples=numAug, augmentedFile=filename_augmented)\n",
    "print(\"mera****************************\")\n",
    "splits = dataset.get_splits()\n",
    "xS_train = []\n",
    "yS_train = []\n",
    "for elem in splits[0][\"train\"][\"X\"]:\n",
    "    xS_train.append(elem)\n",
    "print(xS_train[:3])\n",
    "# print(splits[0][\"train\"][\"y\"])\n",
    "for elem in splits[0][\"train\"][\"y\"]:\n",
    "    if benchmark_dataset == 'AskUbuntu':\n",
    "        yS_train.append(intent_dict_AskUbuntu[elem])\n",
    "    elif benchmark_dataset == 'Chatbot':\n",
    "        yS_train.append(intent_dict_Chatbot[elem])\n",
    "    else:\n",
    "        yS_train.append(intent_dict_WebApplications[elem])\n",
    "\n",
    "print(yS_train)\n",
    "    \n",
    "# print(splits[0][\"train\"][\"y\"][1])\n",
    "# print(splits[0][\"train\"][\"y\"])\n",
    "# for elem in splits[0][\"train\"][\"y\"]:\n",
    "#     print(intent_dict_WebApplications[elem])\n",
    "# print(yS_train[:3])\n",
    "# print(intent_dict_AskUbuntu[elem])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 3, 3, 4, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]\n",
      "[4, 4, 4, 4, 4, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]\n",
      "['how to rocord my screen?', 'how tf record my screen?', 'How to record my screen?', 'how can x highlight or annotate pdfv?', 'hoü can i highlight or annotate pdfs?']\n"
     ]
    }
   ],
   "source": [
    "X_train_raw, y_train_raw = read_CSV_datafile(filename = filename_train)\n",
    "X_test_raw, y_test_raw = read_CSV_datafile(filename = filename_test)\n",
    "print(y_train_raw)\n",
    "\n",
    "X_train_raw = xS_train\n",
    "y_train_raw = yS_train\n",
    "print(y_train_raw)\n",
    "print(X_train_raw[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data samples: \n",
      " ['hjw do i fsx a shutdown proelem?', 'How do I fix a shutdown problem?', 'what graphical utility can ä use for ubuntu auto shutdown?', 'what graphical utilitn can i use for ubuntu auvo shutdown?'] \n",
      "\n",
      "\n",
      "Class Labels: \n",
      " [2, 2, 2, 2] \n",
      "\n",
      "\n",
      "Size of Training Data: 150\n"
     ]
    }
   ],
   "source": [
    "print(\"Training data samples: \\n\",X_train_raw[-5:-1], \"\\n\\n\")\n",
    "\n",
    "print(\"Class Labels: \\n\", y_train_raw[-5:-1], \"\\n\\n\")\n",
    "\n",
    "print(\"Size of Training Data: {}\".format(len(X_train_raw)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(doc):\n",
    "    \"\"\"\n",
    "    Returns a list of strings containing each token in `sentence`\n",
    "    \"\"\"\n",
    "    #return [i for i in re.split(r\"([-.\\\"',:? !\\$#@~()*&\\^%;\\[\\]/\\\\\\+<>\\n=])\",\n",
    "    #                            doc) if i != '' and i != ' ' and i != '\\n']\n",
    "    tokens = []\n",
    "    doc = nlp.tokenizer(doc)\n",
    "    for token in doc:\n",
    "        tokens.append(token.text)\n",
    "    return tokens\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(doc):\n",
    "    clean_tokens = []\n",
    "    doc = nlp(doc)\n",
    "    for token in doc:\n",
    "        if not token.is_stop:\n",
    "            clean_tokens.append(token.lemma_)\n",
    "    return \" \".join(clean_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_ngrams(input_list, n):\n",
    "    return zip(*[input_list[i:] for i in range(n)])\n",
    "\n",
    "def semhash_tokenizer(text):\n",
    "    tokens = text.split(\" \")\n",
    "    final_tokens = []\n",
    "    for unhashed_token in tokens:\n",
    "        hashed_token = \"#{}#\".format(unhashed_token)\n",
    "        final_tokens += [''.join(gram)\n",
    "                         for gram in list(find_ngrams(list(hashed_token), 3))]\n",
    "    return final_tokens\n",
    "\n",
    "def semhash_corpus(corpus):\n",
    "    new_corpus = []\n",
    "    for sentence in corpus:\n",
    "        sentence = preprocess(sentence)\n",
    "        tokens = semhash_tokenizer(sentence)\n",
    "        new_corpus.append(\" \".join(map(str,tokens)))\n",
    "    return new_corpus\n",
    "\n",
    "X_train_raw = semhash_corpus(X_train_raw)\n",
    "X_test_raw = semhash_corpus(X_test_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['#ro roc oco cor ord rd# #sc scr cre ree een en# #?#', '#tf tf# #re rec eco cor ord rd# #sc scr cre ree een en# #?#', '#ho how ow# #re rec eco cor ord rd# #sc scr cre ree een en# #?#', '#x# #hi hig igh ghl hli lig igh ght ht# #an ann nno not ota tat ate te# #pd pdf dfv fv# #?#', '#ho hoü oü# #hi hig igh ghl hli lig igh ght ht# #an ann nno not ota tat ate te# #pd pdf dfs fs# #?#', '#ho how ow# #-P -PR PRO RON ON- N-# #hi hig igh ghl hli lig igh ght ht# #an ann nno not ota tat ate te# #pd pdf df# #?#', '#wo wor ort rth th# #up upg pgr gra rad ade de# #12 12. 2.0 .04 04# #lt lt# #13 13. 3.0 .04 04#', '#wo wor ort rth th# #up upg pgr grü rüd üd# #fr frr rrm rm# #12 12. 2.0 .04 04# #lt lt# #13 13. 3.0 .04 04#', '#be be# #wo wor ort rth th# #up upg pgr gra rad ade de# #12 12. 2.0 .04 04# #lt lts ts# #13 13. 3.0 .04 04#', '#up upg pgr gra rad ade de# #12 12. 2.0 .04 04# #64 64# #bi bit it#', '#up upg pgr gra rad ade de# #12 12. 2.0 .04 04# #64 64# #bt btt tt#', '#up upg pgr gra rad ade de# #12 12. 2.0 .04 04# #64 64# #bi bit it#', '#up upg pgr gra rad ade de# #ub ubu bun unt ntu tu# #14 14. 4.0 .04 04. 4.1 .1# #14 14. 4.0 .04 04. 4.2 .2# #?#', '#ho how ow# #up upg pgr gra rad ade de# #ub ubu bun unt ntu tu# #14 14. 4.0 .04 04. 4.1 .1# #14 14. 4.0 .04 04. 4.2 .2# #?#', '#up upg pgr gra rad ade de# #ub ubu bun unt ntu tu# #14 14. 4.0 .04 04# #15 15. 5.0 .04 04#', '#up upg pgr gra rad ade de# #ub ubu bun unt ntu tu# #14 14. 4.0 .04 04# #15 15. 5.0 .04 04#', '#up upg pgr gra rad ade de# #ub ubu bun unt ntu tu# #15 15. 5.0 .04 04# #td td# #15 15. 5.1 .10 10# #?#', '#up upg pgr gra rad ade de# #lb lbu bun unt ntu tu# #15 15. 5.0 .04 04# #15 15. 5.1 .10 10# #?#', '#up upg pgr gra rad ade de# #ub ubu bun unt ntu tu# #15 15. 5.0 .04 04# #15 15. 5.1 .10 10# #?#', '#up upg pgr gra rad ade de# #12 12. 2.0 .04 04# #12 12. 2.1 .10 10# #us usi sif ifg fg# #st sta tar art rtu tup up# #di dis isk sk#', '#up upg pgr gra rad ade de# #12 12. 2.0 .04 04# #12 12. 2.1 .10 10# #st sta taz azt ztu tup up# #di dis isk sk#', '#up upg pgr gra rad ade de# #12 12. 2.0 .04 04# #12 12. 2.1 .10 10# #st sta tar art rtu tup up# #di dis isk sk#', '#ht htw tw# #up upg pgr grg rgd gde de# #11 11. 1.1 .10 10# #te te# #12 12. 2.0 .04 04# #ha hav ave ve# #ge get et# #pr pro rob obl ble lem em# #?#', '#up upg pgr gra rad ade de# #11 11. 1.1 .10 10# #12 12. 2.0 .04 04# #ha hav ave ve# #ge get et# #pr pro rob obl ble lem em# #?#', '#ho how ow# #up upg pgr gra rad ade de# #11 11. 1.1 .10 10# #12 12. 2.0 .04 04# #ha hav ave ve# #ge get et# #pr pro rob obl ble lem em# #?#', '#up upd pda dat ate te# #11 11. 1.0 .04 04# #12 12. 2.0 .04 04# #li lis ise sec ecd cd#', '#up upd pda dat ate te# #11 11. 1.0 .04 04# #tg tg# #12 12. 2.0 .04 04# #gi git ith th# #li liv ive vec ecd cd#', '#up upd pda dat ate te# #11 11. 1.0 .04 04# #12 12. 2.0 .04 04# #li liv ive vec ecd cd#', '#vo vow ow# #up upg pgr gra rad ade de# #ub ubu bun unt ntu tu# #9. 9.1 .10 10# #12 12. 2.1 .10 10# #te ter erm rmi min ina nal al# #?#', '#up upg pgr gra rad ade de# #ub ubu bun unt ntu tu# #9. 9.1 .10 10# #12 12. 2.1 .10 10# #te ter erm rmi min ina nal al# #?#', '#ho how ow# #up upg pgr gra rad ade de# #ub ubu bun unt ntu tu# #9. 9.1 .10 10# #12 12. 2.1 .10 10# #te ter erm rmi min ina nal al# #?#', '#vo vo# #up upg pgr gra rad ade de# #ub ubu bun unt ntu tu# #10 10. 0.1 .10 10# #11 11. 1.0 .04 04# #?#', '#ho hoü oü# #up upg pgr gra rad ade de# #fx fxo xom om# #ub ubu bun unt ntu tu# #10 10. 0.1 .10 10# #11 11. 1.0 .04 04# #?#', '#ho how ow# #up upg pgr gra rad ade de# #ub ubu bun unt ntu tu# #10 10. 0.1 .10 10# #11 11. 1.0 .04 04# #?#', '#ma mat att tte ter er# #ub ubu bun unt ntu tu# #15 15. 5.0 .04 04# #re rec eco cog ogn gni niz ize ze# #hp hp# #la las ase ser erj rje jet et# #10 102 020 20#', '#öa öat att tte ter er# #ub ubu bun unt ntu tu# #15 15. 5.0 .04 04# #rx rxc xco cog ogn gni niz ize ze# #hp hp# #la las ase ser erj rje jet et# #10 102 020 20#', '#no no# #ma mat att tte ter er# #-P -PR PRO RON ON- N-# #ub ubu bun unt ntu tu# #15 15. 5.0 .04 04# #re rec eco cog ogn gni niz ize ze# #hp hp# #la las ase ser erj rje jet et# #10 102 020 20#', '#se set etu tup up# #hp hp# #pr pri rin int nte ter er# #/# #sc sca can ann nne ner er# #ub ubu bun unt ntu tu# #?#', '#qo qow ow# #se set etu tup up# #hp hp# #pr pri rin int nte ter er# #/# #sc sca can ann nne ner er# #ub ubu bun unt ntu tu# #?#', '#ho how ow# #se set etu tup up# #hp hp# #pr pri rin int nte ter er# #/# #sc sca can ann nne ner er# #ub ubu bun unt ntu tu# #?#', '#se set etu tup up# #hp hp# #c4 c41 414 140 40# #pr pri rin int nte ter er# #wi wir ire rel ele les ess ssl sly ly# #?#', '#se set etu tup up# #hp hp# #c4 c41 414 140 40# #pr pri rin int ntx txr xr# #wi wir ire rel ele les ess ssl sly ly# #?#', '#ho how ow# #-P -PR PRO RON ON- N-# #se set etu tup up# #hp hp# #c4 c41 414 140 40# #pr pri rin int nte ter er# #wi wir ire rel ele les ess ssl sly ly# #?#', '#tß tß# #se set etu tup up# #wi wir ire rel ele les ess ss# #pr pri rin int nt# #pr pri rin int nte ter er# #co con onn nne nec ect ct# #us usb sb# #ßb ßbu bun unt ntu tu# #se ser erv rve ver er# #12 12. 2.1 .10 10# #?#', '#se set etu tup up# #wi wir ire rel ele les ess ss# #pr pri rin int nt# #pr pri rin int nte ter er# #co con onn nne nec ect ct# #fs fsb sb# #oä oä# #ub ubu bun unt ntu tu# #se ser erv rve ver er# #12 12. 2.1 .10 10# #?#', '#ho how ow# #se set etu tup up# #wi wir ire rel ele les ess ss# #pr pri rin int nt# #pr pri rin int nte ter er# #co con onn nne nec ect ct# #us usb sb# #ub ubu bun unt ntu tu# #se ser erv rve ver er# #12 12. 2.1 .10 10# #?#', '#ca caü aü# #in ins nst sta tal all ll# #pa pan ant ntm tmm mm# #25 250 502 02w 2w# #la las ase ser er# #pr pri rin int nte ter er# #ub ubu bun unt ntu tu#', '#ho hod od# #in ins nst sta tal all ll# #pa pan ant ntu tum um# #25 250 502 02w 2w# #la las ase ser er# #pr pri rin int nte ter er# #ub ubu bun unt ntu tu#', '#ho how ow# #-P -PR PRO RON ON- N-# #in ins nst sta tal all ll# #pa pan ant ntu tum um# #25 250 502 02w 2w# #la las ase ser er# #pr pri rin int nte ter er# #ub ubu bun unt ntu tu#', '#in ins nst sta tal all ll# #ca can ano non on# #mp mp5 p56 560 60# #ub ubu bun unt ntu tu# #15 15. 5.0 .04 04#', '#in ins nst sta tal all ll# #ca can ano non on# #mp mp5 p56 560 60# #ub ubu bun unt ntu tu# #15 15. 5.0 .04 04#', '#ho hoj oj# #in ins nst sta tal all ll# #br bro rot oth the her er# #mf mfc fc- c-5 -58 589 890 90c 0cn cn# #ne net etw two wor ork rk# #pr pri rin int nte ter er# #?#', '#qo qo# #in ins nst sta tal all ll# #br bro rot oth the her er# #mf mfc fc- c-5 -58 589 890 90c 0cn cn# #ne net etw two wor ork rk# #pr pri rin int nte ter er# #?#', '#ho how ow# #in ins nst sta tal all ll# #br bro rot oth the her er# #mf mfc fc- c-5 -58 589 890 90c 0cn cn# #ne net etw two wor ork rk# #pr pri rin int nte ter er# #?#', '#j# #in inb nbt bta tal all ll# #dr dri riv ive ver er# #ko kon oni nic ica ca# #mi min ino nol olt lta ta# #20 200 00# #?#', '#in ins nst sta tal all ll# #dr dri riv ive ver er# #ko kon oni nic ica ca# #mi min ino nol olt lta ta# #20 200 00# #?#', '#ho how ow# #-P -PR PRO RON ON- N-# #in ins nst sta tal all ll# #dr dri riv ive ver er# #ko kon oni nic ica ca# #mi min ino nol olt lta ta# #20 200 00# #?#', '#in ins nst sta tal all ll# #dr dri riv ive ver er# #fe fer er# #th thq hq# #pa pan ana nas aso son oni nic ic# #mb mb1 b19 190 900 00c 0cx cx# #-# #-# #pr pri rin int nte ter er# #/# #sc sca can ann nne ner er# #?#', '#in ins nst sta tal all ll# #dr dri riv ive ver er# #pa pan ana nas aso son oni nic ic# #mb mb1 b19 190 900 00c 0cx cx# #-# #-# #pr pri rin int nte ter er# #/# #sc sca can ann nne ner er# #?#', '#ho how ow# #-P -PR PRO RON ON- N-# #in ins nst sta tal all ll# #dr dri riv ive ver er# #pa pan ana nas aso son oni nic ic# #mb mb1 b19 190 900 00c 0cx cx# #al all ll# #-# #-# #on one ne# #pr pri rin int nte ter er# #/# #sc sca can ann nne ner er# #?#', '#in ins nsz sza zal all ll# #ca can ano non on# #lb lbp bp2 p29 290 900 00b 0b# #pr pri rin int nte ter er# #dn dn# #14 14. 4.0 .04 04# #lt lt# #?# #ü# #tr try ry# #me met eth tho hod od# #lb lbr br2 r29 290 900 00# #no not ot# #wo wor ork rk#', '#in ins nst sta tal all ll# #ca can ano non on# #lb lbp bp2 p29 290 900 00b 0b# #pr pri rin int nte ter er# #14 14. 4.0 .04 04# #lt lt# #?# #tr try ry# #me met eth tho hod od# #lb lbp bp2 p29 290 900 00# #no not ot# #wo wor ork rk#', '#ho how ow# #to to# #in ins nst sta tal all ll# #ca can ano non on# #lb lbp bp2 p29 290 900 00b 0b# #pr pri rin int nte ter er# #14 14. 4.0 .04 04# #lt lts ts# #?# #-P -PR PRO RON ON- N-# #tr try ry# #me met eth tho hod od# #lb lbp bp2 p29 290 900 00# #no not ot# #wo wor ork rk#', '#co com omm mma man and nd# #li lin ine ne# #ca cal alc lcu cul ula lat ato tor or# #ub ubu bun unt ntu tu# #?#', '#co com omm mma man and nd# #li lin ink nk# #ca cal alc lcu cul ula lat ato tor or# #ub ubu bun unt ntu tu# #?#', '#an any ny# #co com omm mma man and nd# #li lin ine ne# #ca cal alc lcu cul ula lat ato tor or# #ub ubu bun unt ntu tu# #?#', '#ex ext xtr tra rac act ct# #em emb mbe bed ed# #im ima mag age ge# #pd pdf df#', '#ex ext xtr tra rac act ct# #em emb mbe bed ed# #im ima mag age ge# #n# #pd pdf df#', '#ex ext xtr tra rac act ct# #em emb mbe bed ed# #im ima mag age ge# #pd pdf df#', '#us use se# #qu qui uic ick ckl kly ly# #cu cut ut# #au aud udi dio io# #/# #vi vid ide deo eo#', '#wh wha hat at# #us use se# #qu qui uic ick ckl kly ly# #cu cut ut# #au aud udi dio io# #/# #vi vid ide deo eo#', '#to tor orr rre ren ent nt# #cl cli lie ien ent nt# #co com omm mma man and nd# #-# #li lin ine ne# #?#', '#to tor orr rre ren ent nt# #cx cxi xie ien ent nt# #to tor or# #co com omm mma man and nd# #-# #li lin ine ne# #?#', '#to tor orr rre ren ent nt# #cl cli lie ien ent nt# #co com omm mma man and nd# #-# #li lin ine ne# #?#', '#my mys ysl sll ll# #gu gui ui# #to too ool ol#', '#my mys ysq sql ql# #gu gui ui# #to too ool ol#', '#my mys ysq sql ql# #gu gui ui# #to too ool ols ls#', '#de dev eve vel elo lop ope per er# #te tex ext xt# #ed edi dit ito tor or# #av ava vai aiß ißa ßab abl ble le# #ub ubu bun unt ntu tu# #?#', '#de dev eve vel elo lop ope per er# #te tex ext xt# #ed edi dit ito tor or# #av ava vai ail ila lab abl ble le# #ub ubu bun unt ntu tu# #?#', '#wh wha hat at# #de dev eve vel elo lop ope per er# #te tex ext xt# #ed edi dit ito tor or# #av ava vai ail ila lab abl ble le# #ub ubu bun unt ntu tu# #?#', '#sc scr cre ree een ens nsh sho hot ot# #to too ool ol# #av ava vai ail ila lab abl ble le# #?#', '#sc scr crc rce cen ens nsh sho hot ot# #to too ool ol# #av ava vai ail ila lab abl ble le# #?#', '#wh wha hat at# #sc scr cre ree een ens nsh sho hot ot# #to too ool ol# #av ava vai ail ila lab abl ble le# #?#', '#pr pro rog ogr gra ram am# #us use se# #ed edi dit it# #pd pdf df# #fi fil ile le# #?#', '#wä wäi äic ich ch# #pr pro rog ogr gra ram am# #us use se# #bo bo# #eo eoi oit it# #pd pdm dm# #fi fil ile le# #?#', '#wh whi hic ich ch# #pr pro rog ogr gra ram am# #-P -PR PRO RON ON- N-# #us use se# #ed edi dit it# #pd pdf df# #fi fil ile le# #?#', '#li lig igh ght htw twe wei eig igh ght ht# #to too ool ol# #cr cro rop op# #im ima mag age ge# #qu qui uic ick ckl kly ly# #?#', '#be be# #li lig igh ght htw twe wei eig igh ght ht# #to too ool ol# #cr cro rop op# #im ima mag age ge# #qu qui uic ick ckl kly ly# #?#', '#ir irc rc# #cl cli lie ien ent nt# #av ava vai ail ila lab abl ble le# #?#', '#ir irc rc# #cl cli lie ien ent nt# #dr dre re# #av ava vai ail ila lab abl ble le# #?#', '#wh wha hat at# #ir irc rc# #cl cli lie ien ent nt# #av ava vai ail ila lab abl ble le# #?#', '#ne new ew# #ga gam ame me# #av ava vai ail ila lab abl ble le# #ub ubu bun unt ntu tu# #20 201 011 11# #?#', '#ne new ew# #ga gam ame me# #av ava vai ail ila lab abl ble le# #fo foä oä# #ud udu dun unt ntu tu# #20 201 011 11# #?#', '#wh wha hat at# #ne new ew# #ga gam ame me# #av ava vai ail ila lab abl ble le# #ub ubu bun unt ntu tu# #20 201 011 11# #?#', '#up upn pnp np# #/# #dl dln lna na# #(# #cl cli lie ien ent nt# #)# #pl pla lar are rer er# #re rec eco com omm mme men end nda dat ati tio ion on# #?#', '#ub ubn bnp np# #/# #dl dln lna na# #(# #cl cli lie ien ent nt# #)# #ül üla lay aye yer er# #re rec eco com omm mme men end nda dat ath tho hon on# #?#', '#up upn pnp np# #/# #dl dln lna na# #(# #cl cli lie ien ent nt# #)# #pl pla lay aye yer er# #re rec eco com omm mme men end nda dat ati tio ion on# #?#', '#sc sci cie ien ent nti tif ifß fßc ßc# #pl plo lot ot# #so sof oft ftw twa war are re# #av ava vai ail ila lab abl ble le# #?#', '#öh öha hat at# #sc sci cie ien ent nti tif ifi fic ic# #pl plo lot ot# #so sof oft ftw twa war are re# #av ava vai ail ila lab abl ble le# #?#', '#wh wha hat at# #sc sci cie ien ent nti tif ifi fic ic# #pl plo lot ot# #so sof oft ftw twa war are re# #av ava vai ail ila lab abl ble le# #?#', '#re rec eco com omm mme men end nd# #pa pas ass ssw swo wor ord rd# #ge gen ene ner era rat ato tor or# #?#', '#re rec eco com omm mme meß eßd ßd# #pa pas ass ssw swo wor ord rd# #ge gen ene ner era rat ato tor or# #?#', '#ca can an# #re rec eco com omm mme men end nd# #pa pas ass ssw swo wor ord rd# #ge gen ene ner era rat ato tor or# #?#', '#to too ool ol# #us use se# #mo mon oni nit ito tor or# #we web eb# #se ser erv rve ver er# #?#', '#fo foo ool ol# #us use se# #mo mon oni nit ito tor or# #we web eb# #se ser erv rve ver er# #?#', '#wh wha hat at# #to too ool ol# #us use se# #mo mon oni nit ito tor or# #we web eb# #se ser erv rve ver er# #?#', '#go goo ood od# #mo mon ong ngo god odb db# #gu gui ui# #cm cmi mie ien ent nt# #?#', '#go goo ood od# #mo mon ong ngo god odb db# #gu gui ui# #cl cli lie ien ent nt# #?#', '#wh wha hat at# #go goo ood od# #mo mon ong ngo god odb db# #gu gui ui# #cl cli lie ien ent nt# #?#', '#pa pas ass ssw swo wor ord rd# #ma man ana nag age gem eme men ent nt# #ap app ppl pli lic ica cat ati tio ion on# #?#', '#pa pas ass ssw swo wor ord rd# #ma man ana nag age gem eme men ent nt# #ap app ppl pli lic ica cat ati tio ion ons ns# #?#', '#ap app ppl pli lic ica cat ati tio ion on# #re rea ead ad# #mo mob obi bi# #fi fil ily ly# #?#', '#ap app ppl pli lic ica cat ati tio ion on# #re rea ead ad# #mo moä oäi äi# #fi fil ile leü eü# #?#', '#be be# #ap app ppl pli lic ica cat ati tio ion on# #re rea ead ad# #mo mob obi bi# #fi fil ile le# #?#', '#sh shu hut ut# #ex ext xtr tra ra# #qu que ues est sti tio ion on#', '#sh shx hxt xt# #ex ext xtr tra ra# #qu que ues est sti tio ion on#', '#sh shu hut ut# #ex ext xtr tra ra# #qu que ues est sti tio ion on#', '#sh shp hpt ptd tdo dow own wn# #cb cbm bmp mpu put ute ter er# #us use ser er# #lo log og# #?#', '#sb sbu but utd tdo dow own wn# #co com omp mpu put ute ter er# #wf wfe fen en# #us use ser er# #lo log og# #?#', '#ho how ow# #sh shu hut utd tdo dow own wn# #co com omp mpu put ute ter er# #us use ser er# #lo log og# #?#', '#ws wsa sat at# #pr pro rop ope per er# #te ter erm rmi min ina nal al# #-# #wa way ay# #sh shu hut utd tdo dow own wn# #?#', '#pr pro rop ope per er# #te ter erm rmi min ina nal al# #-# #wa way ay# #sh shu hut utd tdo dow own wn# #?#', '#wh wha hat at# #pr pro rop ope per er# #te ter erm rmi min ina nal al# #-# #wa way ay# #sh shu hut utd tdo dow own wn# #?#', '#au aut uto tom oma mat ati tic ica cal all lly ly# #sh shu hut utd tdo dow own wn# #tz tze ze# #sy sys yst ste tem em# #sp spe pec eci cif ifi fic ic# #ti tim ime me# #?#', '#au aut uto tom oma mat ati tic ica cal all lly ly# #sh shu hut utd tdo dow own wn# #sy sys yst ste tem em# #sp spe pec eci cif ifi fic ic# #ti tim ime me# #?#', '#ho how ow# #-P -PR PRO RON ON- N-# #au aut uto tom oma mat ati tic ica cal all lly ly# #sh shu hut utd tdo dow own wn# #sy sys yst ste tem em# #sp spe pec eci cif ifi fic ic# #ti tim ime me# #?#', '#hz hzt ztk tke key ey# #sh shu hut ut# #lo log ogi gin in# #sc scr cre ree een en# #?#', '#ho hot otk tke key ey# #sh shu hut ut# #lo log ogi gin in# #sc scr cre ree een en# #?#', '#ho hot otk tke key ey# #sh shu hut ut# #lo log ogi gin in# #sc scr cre ree een en# #?#', '#sh shu hut utd tdo dow own wn# #co com omp mpu put ute ter er# #xs xse ses ess ssi sio ion on# #en end nd# #?#', '#sh shu hut utd tdo dow own wn# #co coq oqp qpu put ute ter er# #xs xse ses ess ssi sio ion on# #en end nd# #?#', '#ho how ow# #sh shu hut utd tdo dow own wn# #co com omp mpu put ute ter er# #xs xse ses ess ssi sio ion on# #en end nd# #?#', '#un une ne# #sh shu hut utd tdo dow own wn# #pj pj# #de dey eyb ybo boa oar ard rd# #?#', '#sh shu hut utd tdo dow own wn# #f# #pc pc# #ke key eyb ybo boa oar ard rd# #?#', '#ho how ow# #sh shu hut utd tdo dow own wn# #pc pc# #ke key eyb ybo boa oar ard rd# #?#', '#en ena nab abl ble le# #sh shu hut utd tdo dow own wn# #ve ver erb rbo bos osi sit ity ty# #?#', '#ho how ow# #-P -PR PRO RON ON- N-# #en ena nab abl ble le# #sh shu hut utd tdo dow own wn# #ve ver erb rbo bos osi sit ity ty# #?#', '#an anb nb# #ke key eyb ybo boa oar ard rd# #sh sho hor ort rtc tcu cut ut# #sh shu hut utd tdo dow own wn# #?#', '#ke key eyb ybo boa oar ard rd# #sh sho hor ort rtc tcu cut ut# #sh shu hut utd tdo dow own wn# #?#', '#be be# #ke key eyb ybo boa oar ard rd# #sh sho hor ort rtc tcu cut uts ts# #sh shu hut utd tdo dow own wn# #?#', '#sh shu hut utd tdo dow own wn# #ce cer ert rta tai ain in# #ti tim ime me#', '#sh shu hut utd tdo dow own wn# #ce cer ert rta tai ain in# #ti tim ime me#', '#sh shu hut utd tdo dow own wn# #pr pro rob obl ble lem em# #ub ubu bun unt ntu tu# #16 16. 6.0 .04 04#', '#sh shu hut utd tdo dow own wn# #pr pro rob obl ble lem em# #ub ubu bun unt ntu tu# #16 16. 6.0 .04 04#', '#fi fix ix# #g# #sh shu hut utd tdo dow own wn# #pr pro rob obl ble lem em# #?#', '#hj hjw jw# #fs fsx sx# #sh shu hut utd tdo dow own wn# #pr pro roe oel ele lem em# #?#', '#ho how ow# #-P -PR PRO RON ON- N-# #fi fix ix# #sh shu hut utd tdo dow own wn# #pr pro rob obl ble lem em# #?#', '#gr gra rap aph phi hic ica cal al# #ut uti til ili lit ity ty# #ä# #us use se# #ub ubu bun unt ntu tu# #au aut uto to# #sh shu hut utd tdo dow own wn# #?#', '#gr gra rap aph phi hic ica cal al# #ut uti til ili lit itn tn# #us use se# #ub ubu bun unt ntu tu# #au auv uvo vo# #sh shu hut utd tdo dow own wn# #?#', '#wh wha hat at# #gr gra rap aph phi hic ica cal al# #ut uti til ili lit ity ty# #-P -PR PRO RON ON- N-# #us use se# #ub ubu bun unt ntu tu# #au aut uto to# #sh shu hut utd tdo dow own wn# #?#']\n"
     ]
    }
   ],
   "source": [
    "X_train_raw[:5]\n",
    "print(X_train_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vectorizer(corpus, preprocessor=None, tokenizer=None):\n",
    "    vectorizer = CountVectorizer(ngram_range=(2,4),analyzer='char')\n",
    "    vectorizer.fit(corpus)\n",
    "    return vectorizer, vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import metrics\n",
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trim(s):\n",
    "    \"\"\"Trim string to fit on terminal (assuming 80-column display)\"\"\"\n",
    "    return s if len(s) <= 80 else s[:77] + \"...\"\n",
    "\n",
    "\n",
    "# #############################################################################\n",
    "# Benchmark classifiers\n",
    "def benchmark(clf, X_train, y_train, X_test, y_test, target_names,\n",
    "              print_report=True, feature_names=None, print_top10=False,\n",
    "              print_cm=True):\n",
    "    print(target_names)\n",
    "    print('_' * 80)\n",
    "    print(\"Training: \")\n",
    "    print(clf)\n",
    "    t0 = time()\n",
    "    clf.fit(X_train, y_train)\n",
    "    train_time = time() - t0\n",
    "    print(\"train time: %0.3fs\" % train_time)\n",
    "\n",
    "    t0 = time()\n",
    "    pred = clf.predict(X_test)\n",
    "    test_time = time() - t0\n",
    "    print(\"test time:  %0.3fs\" % test_time)\n",
    "\n",
    "    score = metrics.accuracy_score(y_test, pred)\n",
    "    print(\"accuracy:   %0.3f\" % score)\n",
    "    #print(\"Accuracy: %0.3f (+/- %0.3f)\" % (score.mean(), score.std() * 2))\n",
    "\n",
    "    if hasattr(clf, 'coef_'):\n",
    "        print(\"dimensionality: %d\" % clf.coef_.shape[1])\n",
    "        print(\"density: %f\" % density(clf.coef_))\n",
    "\n",
    "        if print_top10 and feature_names is not None:\n",
    "            print(\"top 10 keywords per class:\")\n",
    "            for i, label in enumerate([\"Download Video\", \"Change Password\", \"None\", \"Export Data\", \"Sync Accounts\",\n",
    "                  \"Filter Spam\", \"Find Alternative\", \"Delete Account\"]):\n",
    "                top10 = np.argsort(clf.coef_[i])[-10:]\n",
    "                print(trim(\"%s: %s\" % (label, \" \".join([feature_names[i] for i in top10]))))\n",
    "        print()\n",
    "\n",
    "    if print_report:\n",
    "        print(\"classification report:\")\n",
    "        print(y_test, \"y_test\", target_names, \"target_names\", \"pred\", pred)\n",
    "        print(metrics.classification_report(y_test, pred,\n",
    "                                            target_names=target_names))\n",
    "\n",
    "    if print_cm:\n",
    "        print(\"confusion matrix:\")\n",
    "        print(metrics.confusion_matrix(y_test, pred))\n",
    "\n",
    "    print()\n",
    "    clf_descr = str(clf).split('(')[0]\n",
    "    return clf_descr, score, train_time, test_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_results(results, nameClass):\n",
    "    # make some plots\n",
    "    indices = np.arange(len(results))\n",
    "\n",
    "    results = [[x[i] for x in results] for i in range(4)]\n",
    "\n",
    "    clf_names, score, training_time, test_time = results\n",
    "    training_time = np.array(training_time) / np.max(training_time)\n",
    "    test_time = np.array(test_time) / np.max(test_time)\n",
    "\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    plt.title(\"Score\")\n",
    "    plt.barh(indices, score, .2, label=\"score\", color='navy')\n",
    "    plt.barh(indices + .3, training_time, .2, label=\"training time\",\n",
    "             color='c')\n",
    "    plt.barh(indices + .6, test_time, .2, label=\"test time\", color='darkorange')\n",
    "    plt.yticks(())\n",
    "    plt.legend(loc='best')\n",
    "    plt.subplots_adjust(left=.25)\n",
    "    plt.subplots_adjust(top=.95)\n",
    "    plt.subplots_adjust(bottom=.05)\n",
    "\n",
    "    for i, c in zip(indices, clf_names):\n",
    "        plt.text(-.3, i, c)\n",
    "    print(benchmark,nameClass, numAug)\n",
    "    plt.savefig(\"./results_\"+benchmark_dataset+nameClass+str(numAug)+\".png\", format=\"png\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_ver_bars(results, nameClass):\n",
    "        \"\"\" Plot the results of the tests in a vertical fashion\n",
    "            @param: results list of lists of results\"\"\"\n",
    "        indices = np.arange(len(results))\n",
    "\n",
    "        results = [[x[i] for x in results] for i in range(4)] #4 was len(results)\n",
    "\n",
    "        #save_file(\"outlook.txt\", results)\n",
    "        clf_names, score, training_time, test_time = results\n",
    "#        print(results, \"func\", indices, \"indices\", clf_names, \"clf_names\" )\n",
    "        training_time = np.array(training_time) / np.max(training_time)\n",
    "        test_time = np.array(test_time) / np.max(test_time)\n",
    "        log_training_time = np.log10(training_time)\n",
    "        log_test_time = np.log10(test_time)\n",
    "        fig = plt.figure(figsize=(12, 8))\n",
    "        ax = fig.add_subplot(111)\n",
    "\n",
    "#         ax.set_yscale('log')\n",
    "#         labels = np.array([0, 0.005, 0.01, 0.017, 0.22, 0.035, 0.05, 0.07, 0.1, 0.15, 0.3, 0.5, 0.7, 1.0])\n",
    "        labels = training_time\n",
    "        ax.set_yticks(labels)\n",
    "#        ax.yaxis.set_major_formatter(ticker.FormatStrFormatter(\"%d\"))\n",
    "#         ax.yaxis.set_major_formatter(ticker.ScalarFormatter())\n",
    "#        ax.set_ylim([0., 2.])\n",
    "##        fig1, ax1 = plt.subplots()\n",
    "#         ax.get_xaxis().get_major_formatter().labelOnlyBase = False\n",
    "#        plt.yscale('log')\n",
    "        plt.grid(True)\n",
    "#        matplotlib.pyplot.autoscale(True, axis='both')\n",
    "        plt.title(\"With n augmented data/class\")\n",
    "#        plt.ylim(0.6, 1.0)\n",
    "#        plt.ylim(0.0,1.0)\n",
    "#        labels = np.arange(0,1.05,0.05)\n",
    "#        plt.xticks(labels, labels)\n",
    "#        plt.yticks(labels, labels)\n",
    "        plt.yticks([0.6,0.7,0.8, 0.85, 0.88, 0.91,0.94,0.97,1.0])\n",
    "        plt.bar(indices, score, .1, label=\"accuracy\", color='navy') #.4 was .2 in all\n",
    "        plt.bar(indices + 0.3, training_time, .1, label=\"training time\", color='c')\n",
    "        plt.bar(indices + 0.6, test_time, .1, label=\"test time\", color='darkorange')\n",
    "#        for log time with matplotlib ^\n",
    "#        plt.bar(indices + .3, log_training_time, .2, label=\"training time\", color='c')\n",
    "#        plt.bar(indices + .6, log_test_time, .2, label=\"test time\", color='darkorange')\n",
    "        plt.xlabel(\"Classifier \"+ nameClass)\n",
    "        plt.ylabel(\"Accuracy\")\n",
    "#         plt.ylabel(\"Log(Time)\")\n",
    "        #plt.yscale('log')\n",
    "\n",
    "#         plt.xticks(())\n",
    "        plt.legend(loc='lower right') #instead of 4\n",
    "        plt.subplots_adjust(left=.05)\n",
    "        plt.subplots_adjust(top=.90)\n",
    "        plt.subplots_adjust(bottom=.15)\n",
    "#        \n",
    "\n",
    "#        plt.set_yscale('log')\n",
    "\n",
    "\n",
    "        for i, c, t in zip(indices, clf_names, test_time):\n",
    "#             plt.text(i, t+0.002, c, rotation=-30, clip_on=True) #was -0.05 instead of 1\n",
    "            print(i,c) #to set the text of the plots i needed to check them\n",
    "            # plt.savefig(\"./plots/\"+c+\".png\", format=\"png\")\n",
    "        \n",
    "        plt.savefig(\"./results_vert_\"+benchmark_dataset+nameClass+str(numAug)+\".png\", format=\"png\")\n",
    "        plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_for_training():\n",
    "    vectorizer, feature_names = get_vectorizer(X_train_raw, preprocessor=preprocess, tokenizer=tokenize)\n",
    "    \n",
    "    X_train = vectorizer.transform(X_train_raw).toarray()\n",
    "    X_test = vectorizer.transform(X_test_raw).toarray()\n",
    "            \n",
    "    return X_train, y_train_raw, X_test, y_test_raw, feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Split 0\n",
      "Train Size: 150\n",
      "Test Size: 109\n",
      "================================================================================\n",
      "gridsearchRF\n",
      "['Make Update', 'Setup Printer', 'Shutdown Computer', 'Software Recommendation', 'None']\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
      "       estimator=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=None,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False),\n",
      "       fit_params=None, iid='warn', n_jobs=None,\n",
      "       param_grid={'n_estimators': [10, 20, 40, 50, 100, 70], 'min_samples_leaf': [1, 3, 5, 11, 25], 'max_features': [0.5, 1]},\n",
      "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
      "       scoring=None, verbose=0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pedroalonso/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/model_selection/_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n",
      "/Users/pedroalonso/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train time: 45.821s\n",
      "test time:  0.010s\n",
      "accuracy:   0.908\n",
      "classification report:\n",
      "[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 0, 3, 0, 4, 3, 4, 4, 4, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1] y_test ['Make Update', 'Setup Printer', 'Shutdown Computer', 'Software Recommendation', 'None'] target_names pred [3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 3 3 0 0 3 3 3 3 2 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "                         precision    recall  f1-score   support\n",
      "\n",
      "            Make Update       0.92      0.95      0.93        37\n",
      "          Setup Printer       1.00      1.00      1.00        13\n",
      "      Shutdown Computer       0.88      1.00      0.93        14\n",
      "Software Recommendation       0.88      0.93      0.90        40\n",
      "                   None       0.00      0.00      0.00         5\n",
      "\n",
      "              micro avg       0.91      0.91      0.91       109\n",
      "              macro avg       0.74      0.77      0.75       109\n",
      "           weighted avg       0.87      0.91      0.89       109\n",
      "\n",
      "confusion matrix:\n",
      "[[35  0  1  1  0]\n",
      " [ 0 13  0  0  0]\n",
      " [ 0  0 14  0  0]\n",
      " [ 3  0  0 37  0]\n",
      " [ 0  0  1  4  0]]\n",
      "\n",
      "0 GridSearchCV\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# for numRun in range(10):\n",
    "    #increment the num of DA values\n",
    "for i_s, split in enumerate(range(1)):\n",
    "    print(\"Evaluating Split {}\".format(i_s))\n",
    "    X_train, y_train, X_test, y_test, feature_names = data_for_training()\n",
    "    if benchmark_dataset == 'Chatbot':\n",
    "        target_names = [\"DepartureTime\",\"FindConnection\"]\n",
    "    elif benchmark_dataset == 'WebApplication':\n",
    "        target_names = [\"Download Video\", \"Change Password\", \"None\", \"Export Data\", \"Sync Accounts\",\n",
    "                  \"Filter Spam\", \"Find Alternative\", \"Delete Account\"]\n",
    "    else:\n",
    "        target_names = [\"Make Update\", \"Setup Printer\", \"Shutdown Computer\", \"Software Recommendation\", \"None\"]\n",
    "        \n",
    "    print(\"Train Size: {}\\nTest Size: {}\".format(X_train.shape[0], X_test.shape[0]))\n",
    "    results = []\n",
    "    \n",
    "    parameters_RF={ \"n_estimators\" : [10,20,40,50,100,70],\n",
    "           \"min_samples_leaf\" : [1,3,5,11,25],\n",
    "                  \"max_features\" : [0.5,1]}\n",
    "    \n",
    "    for clf, name in [ \n",
    "        (GridSearchCV(RandomForestClassifier(n_estimators=10),parameters_RF, cv=5),\"gridsearchRF\")\n",
    "        ]:\n",
    "        print('=' * 80)\n",
    "        print(name)\n",
    "        results.append(benchmark(clf, X_train, y_train, X_test, y_test, target_names, feature_names=feature_names))\n",
    "        \n",
    "#         plot_results(results, nameClass='RF')\n",
    "        plot_ver_bars(results,nameClass='RF')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Split 0\n",
      "Train Size: 150\n",
      "Test Size: 109\n",
      "================================================================================\n",
      "gridsearchmlp\n",
      "['Make Update', 'Setup Printer', 'Shutdown Computer', 'Software Recommendation', 'None']\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "GridSearchCV(cv=8, error_score='raise-deprecating',\n",
      "       estimator=MLPClassifier(activation='tanh', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=(100,), learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
      "       n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
      "       random_state=None, shuffle=True, solver='adam', tol=0.0001,\n",
      "       validation_fraction=0.1, verbose=False, warm_start=False),\n",
      "       fit_params=None, iid='warn', n_jobs=None,\n",
      "       param_grid={'hidden_layer_sizes': [(100, 50), (300, 100), (300, 200, 100)]},\n",
      "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
      "       scoring=None, verbose=0)\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "for i_s, split in enumerate(range(1)):\n",
    "    print(\"Evaluating Split {}\".format(i_s))\n",
    "    X_train, y_train, X_test, y_test, feature_names = data_for_training()\n",
    "    #target_names = [\"DepartureTime\",\"FindConnection\"]\n",
    "#     target_names = [\"Download Video\", \"Change Password\", \"None\", \"Export Data\", \"Sync Accounts\",\n",
    "#                   \"Filter Spam\", \"Find Alternative\", \"Delete Account\"]\n",
    "    if benchmark_dataset == 'Chatbot':\n",
    "        target_names = [\"DepartureTime\",\"FindConnection\"]\n",
    "    elif benchmark_dataset == 'WebApplication':\n",
    "        target_names = [\"Download Video\", \"Change Password\", \"None\", \"Export Data\", \"Sync Accounts\",\n",
    "                  \"Filter Spam\", \"Find Alternative\", \"Delete Account\"]\n",
    "    else:\n",
    "        target_names = [\"Make Update\", \"Setup Printer\", \"Shutdown Computer\", \"Software Recommendation\", \"None\"]\n",
    "    \n",
    "    print(\"Train Size: {}\\nTest Size: {}\".format(X_train.shape[0], X_test.shape[0]))\n",
    "    results = []\n",
    "    parameters_mlp={'hidden_layer_sizes':[(100,50), (300, 100),(300,200,100)]}\n",
    "    for clf, name in [\n",
    "        (GridSearchCV(MLPClassifier(activation='tanh'),parameters_mlp, cv=8),\"gridsearchmlp\")\n",
    "        ]:\n",
    "        print('=' * 80)\n",
    "        print(name)\n",
    "        results.append(benchmark(clf, X_train, y_train, X_test, y_test, target_names,\n",
    "                                 feature_names=feature_names))\n",
    "        \n",
    "#         plot_results(results, nameClass=\"MLP\")\n",
    "        plot_ver_bars(results, nameClass='MLP')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py36",
   "language": "python",
   "name": "py36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
